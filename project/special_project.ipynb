{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2019:][iapr2019] Special project\n",
    "\n",
    "**Group members:**\n",
    "    1- first name and last name,\n",
    "    2- first name and last name,\n",
    "    3- first name and last name\n",
    "\n",
    "**Due date:** 30.05.2019\n",
    "\n",
    "[iapr2019]: https://github.com/LTS5/iapr-2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Please find the description of this special project via [this link].\n",
    "\n",
    "[this link]: https://github.com/LTS5/iapr-2019/blob/master/project/special_project_description.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  51\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import skimage.color\n",
    "\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'project-data'\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "\n",
    "# with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "#     tar.extractall(path=data_base_path)\n",
    "\n",
    "# **** type = test, train, validation ****\n",
    "type = \"test\"\n",
    "\n",
    "# Load images\n",
    "file_ = open(os.path.join(data_base_path, data_folder, type + \".txt\"), \"r\")\n",
    "im_names = []\n",
    "name_i = file_.readline()\n",
    "im_names.append(name_i[0:(len(name_i)-1)])\n",
    "while (name_i):\n",
    "    name_i = file_.readline()\n",
    "    im_names.append(name_i[0:(len(name_i)-1)])\n",
    "\n",
    "filenames = [os.path.join(data_base_path, data_folder,\"images\", type, name) + '.jpg' for name in im_names]\n",
    "test = skimage.io.imread_collection(filenames)\n",
    "print('Number of images: ', len(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Finding varroas by segmentation\n",
    "Add your implementation for ''**detect_by_segmentation**'' function. Please make sure the input and output follows the mentioned format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "import numpy as np\n",
    "from skimage.morphology import disk, square\n",
    "\n",
    "\n",
    "# Function that rescales the intensity value and sets it between 0 and 255\n",
    "def rescale_intensity(image):\n",
    "    y_im, x_im, z_im = image.shape\n",
    "    out = image.copy()\n",
    "    for i in range(0,z_im):\n",
    "        image2 = image[:,:,i]\n",
    "        minimum = np.min(image2)\n",
    "        maximum = np.max(image2)\n",
    "        out[:,:,i]=(image2 - minimum)/(maximum-minimum)*255\n",
    "    return out\n",
    "\n",
    "# Function that, using K-Means, finds the centers of each element in the image that is not part of the background.\n",
    "# Furthermore, each element is labelled\n",
    "def treshold_varroa(image):\n",
    "    out = image[:,:,0].copy()\n",
    "    image = rescale_intensity(image)\n",
    "    y_im, x_im, z_im = image.shape\n",
    "    X_r = np.reshape(image[:,:,0], (x_im*y_im))\n",
    "    X_g = np.reshape(image[:,:,1], (x_im*y_im))\n",
    "    X_b = np.reshape(image[:,:,2], (x_im*y_im))\n",
    "\n",
    "    X = np.array([X_r, X_g, X_b])\n",
    "    X = np.transpose(X)\n",
    "\n",
    "    #plt.scatter(X[:, 0], X[:, 2], s=1);\n",
    "\n",
    "    from sklearn.cluster import KMeans\n",
    "    kmeans = KMeans(n_clusters=3)\n",
    "    kmeans.fit(X)\n",
    "    y_kmeans = kmeans.predict(X)\n",
    "\n",
    "    #plt.scatter(X[:, 0], X[:, 2], c=y_kmeans, s=1, cmap='viridis')\n",
    "\n",
    "    centers = kmeans.cluster_centers_\n",
    "    #plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);\n",
    "\n",
    "    y_kmeans = np.reshape(y_kmeans, (y_im,x_im))\n",
    "    get_indexes = lambda x, xs: [i for (y, i) in zip(xs, range(len(xs))) if x == y]\n",
    "    label_ = centers[:,0].argmin()\n",
    "    for x in range(0,x_im):\n",
    "        for y in range(0,y_im):\n",
    "            if y_kmeans[y,x]==label_ :\n",
    "                out[y,x]=0\n",
    "            else:\n",
    "                out[y,x]=255\n",
    "    return out\n",
    "\n",
    "\n",
    "def inverse_image(image):\n",
    "    # This function only works for thresholded images and it inverses the blak pixels with the white pixels and vice versa.\n",
    "    # It is usefull when we use morphological operations because they work on the logical ones and not on the zeros.\n",
    "    out = image.copy()\n",
    "    y_image, x_image = image.shape\n",
    "    for x in range(0,x_image):\n",
    "        for y in range(0,y_image):\n",
    "            if image[y,x]==0:\n",
    "                out[y,x]=255\n",
    "            else:\n",
    "                out[y,x]=0\n",
    "    return out\n",
    "\n",
    "# Function that creates a histogram which counts the varroas in each image\n",
    "def create_histogram(image, xmin, ymin, xmax, ymax):\n",
    "    # This function looks in a rectangle from xmin to xmax, from ymin to ymax how many different labels are present and it\n",
    "    # create a histogram\n",
    "    max_label = np.max(image)\n",
    "    count_label_j = np.zeros(max_label-1)\n",
    "    for x in range(xmin,xmax+1):\n",
    "        for y in range(ymin,ymax+1):\n",
    "            for j in range(0,max_label-1):\n",
    "                # j+2 because the array starts at zero and the label at 1, and the lable 1 corresponds to the background and we don't want it \n",
    "                if image[y,x] == j+2 :\n",
    "                    count_label_j[j] = count_label_j[j] + 1\n",
    "    return count_label_j\n",
    "\n",
    "def extract_varroa(image_lab, label_varroa):\n",
    "    # This function extracts the varroa having the label \"label_varroa\" on the image \"i\"\n",
    "    # The output is a thresholded image with the varroa's pixels in black, the function also returns the number \n",
    "    # of pixels of this varroa\n",
    "    image = image_lab.copy()\n",
    "    y_image, x_image = image.shape\n",
    "    for x in range(0,x_image):\n",
    "        # This is an inversed threshold, because the morphological operations are working on the true values\n",
    "        for y in range(0,y_image):\n",
    "            if image_lab[y,x] == label_varroa:\n",
    "                image[y,x] = 255\n",
    "            else:\n",
    "                image[y,x] = 0\n",
    "    # We applie a dilation because previously we applied an erosion in order to separate the superposed varroas\n",
    "    # and now we would like to obtain the entire varroa\n",
    "    image = skimage.morphology.dilation(image,disk(int(varona_size*0.85)))\n",
    "    \n",
    "    # After the morphological operation we reverse the image\n",
    "    image = inverse_image(image)\n",
    "    \n",
    "    \n",
    "    x_min = x_image\n",
    "    x_max = 0\n",
    "    y_min = y_image\n",
    "    y_max = 0\n",
    "    for x in range(0,x_image):\n",
    "        for y in range(0,y_image):\n",
    "            if image[y,x]==0:\n",
    "                if x < x_min:\n",
    "                    x_min = x\n",
    "                if x > x_max:\n",
    "                    x_max = x\n",
    "                if y < y_min:\n",
    "                    y_min = y\n",
    "                if y > y_max:\n",
    "                    y_max = y\n",
    "    h = y_max-y_min\n",
    "    w = x_max-x_min\n",
    "    \n",
    "    return x_min, y_min, w, h\n",
    "\n",
    "little_hole = 2\n",
    "varona_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_by_segmentation(img):\n",
    "    '''\n",
    "    Input: One single image\n",
    "    Output: A numpy array containing coordonates of all detected varroas, with the following format: \n",
    "            [[x_1, y_1, w_1, h_2], [x_2, y_2, w_1, h_2], ..., [x_n, y_n, w_n, h_n]] \n",
    "            where ''n'' is the number of detected varroas.\n",
    "    '''\n",
    "    # Patrick wrote here\n",
    "    \n",
    "    \n",
    "    image = treshold_varroa(img).copy()\n",
    "    # We inverse the image because the morphological operations work only on the true elements and not with\n",
    "    # the false\n",
    "    image = inverse_image(image)\n",
    "    \n",
    "    # We close the little holes present in the varroas\n",
    "    image = skimage.morphology.closing(image,square(little_hole))\n",
    "    \n",
    "    # We open with a circle a bit bigger than the varroa size and we subtract it from the original image\n",
    "    # with this apprach we eliminate the parts bigger than a varroa\n",
    "    image = image - skimage.morphology.opening(image,disk(int(varona_size*1.7)))\n",
    "    \n",
    "    # We open with a circle a bit smaller than the size of the varroa, like this all the parts smaller than a varroa are deleted\n",
    "    image = skimage.morphology.opening(image,disk(varona_size))\n",
    "    \n",
    "    # In order to label correctly the varroas they don't have to be superposed and we do an erosion with\n",
    "    # a circle smaller than the size of the varroa\n",
    "    image = skimage.morphology.erosion(image,disk(int(varona_size*0.85)))\n",
    "    \n",
    "    image = inverse_image(image)\n",
    "    image_thresholded2 = image.copy()\n",
    "    image_thresholded2 = image.astype(int)*255\n",
    "    \n",
    "    image_labeled = skimage.measure.label(image_thresholded2, connectivity=2, background=255)\n",
    "    \n",
    "    nbr_varroas = np.max(image) - 1\n",
    "    \n",
    "    # for label_varroa from 2 to nbr_varroas+1\n",
    "    label_varroa = 2\n",
    "    x_min, y_min, w, h = extract_varroa(image_labeled, label_varroa)\n",
    "    \n",
    "    return x_min, y_min, w, h\n",
    "    #Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your implementation. Report the Precision, Recall and F1-score, by using all 50 images of the test-set, and considering 0.3 as the IoU threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877, 1297, 15, 16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "detect_by_segmentation(test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement your first detector\n",
    "\n",
    "Write your function(s) for the second part. Feel free to change the name of the function and add your additional functions, but please make sure their input and output follows the mentioned format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_by_method_1(img):\n",
    "    '''\n",
    "    Input: One single image\n",
    "    Output: A numpy array containing coordonates of all detected varroas, with the following format: \n",
    "            [[x_1, y_1, w_1, h_2], [x_2, y_2, w_1, h_2], ..., [x_n, y_n, w_n, h_n]] \n",
    "            where ''n'' is the number of detected varroas.\n",
    "    '''\n",
    "\n",
    "    #Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your implementation. Report the Precision, Recall and F1-score, by using all 50 images of the test-set, and considering 0.3 as the IoU threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Using MLP and CNNs\n",
    "\n",
    "Add your implementation for the thrid part. Feel free to add your desirable functions, but please make sure you have proper functions for the final detection, where their input and output follows the same format as the previous parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You can generate a json submission file by using the function ''**generate_pred_json**''. This prediction file can be uploaded online for evaluation (Please refer to section 3 of the project description for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def generate_pred_json(data, tag='baseline'):\n",
    "    '''\n",
    "    Input\n",
    "    - data: Is a dictionary d, such that:\n",
    "          d = { \n",
    "              \"ID_1\": [], \n",
    "              \"ID_2\": [[x_21, y_21, w_21, h_21], [x_22, y_22, w_22, h_22]], \n",
    "              ... \n",
    "              \"ID_i\": [[x_i1, y_i1, w_i1, h_i1], ..., [x_iJ, y_iJ, w_iJ, h_iJ]],\n",
    "              ... \n",
    "              \"ID_N\": [[x_N1, y_N1, w_N1, h_N1]],\n",
    "          }\n",
    "          where ID is the string id of the image (e.i. 5a05e86fa07d56baef59b1cb_32.00px_1) and the value the Kx4 \n",
    "          array of intergers for the K predicted bounding boxes (e.g. [[170, 120, 15, 15]])\n",
    "    - tag: (optional) string that will be added to the name of the json file.\n",
    "    Output\n",
    "      Create a json file, \"prediction_[tag].json\", conatining the prediction to EvalAI format.\n",
    "    '''\n",
    "    unvalid_key = []\n",
    "    _data = data.copy()\n",
    "    for key, value in _data.items():\n",
    "        try:\n",
    "            # Try to convert to numpy array and cast as closest int\n",
    "            print(key)\n",
    "            v = np.around(np.array(value)).astype(int)\n",
    "            # Check is it is a 2d array with 4 columns (x,y,w,h)\n",
    "            if v.ndim != 2 or v.shape[1] != 4:\n",
    "                unvalid_key.append(key)\n",
    "            # Id must be a string\n",
    "            if not isinstance(key, str):\n",
    "                unvalid_key.append(key)\n",
    "            _data[key] = v.tolist()\n",
    "        # Deal with not consistant array size and empty predictions\n",
    "        except (ValueError, TypeError):\n",
    "            unvalid_key.append(key)\n",
    "    # Remove unvalid key from dictionnary\n",
    "    for key in unvalid_key: del _data[key]\n",
    "    \n",
    "    with open('prediction_{}.json'.format(tag), 'w') as outfile:\n",
    "        json.dump(_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
